
---
title: "Clustering Credit Card Customers for Targeted Marketing using Unsupervised Learning"
output: html_document
---

# CSML1000 Project #2, by Group 8
Tamer Hanna <tamerh@my.yorku.ca>
Pete Gray <ptgray@my.yorku.ca>
Xiaohai Lu <yu271637@my.yorku.ca>
Haofeng Zhou <zhf85@my.yorku.ca>

```{r message=FALSE, warning=FALSE}
library(dplyr);
library(ggplot2);
library(knitr);
library(validate);
```

# OVERVIEW

Using data on the behaviour of credit card customers, we can use unsupervised learning to discover market segments that would be useful for targeting marketing strategies.

Our dataset has 19 columns of data on 9000 customers. Using K-means and PCA, we can determine an optimal number of market segments, discover the identifying properties of those segments, and be able to describe to the marketing department what the most significant behaviours of the people in those segments are. Marketing campaigns, then, can be targeted at, for example, impulse shoppers, big spenders, or people who have a hard time paying off their debts.

# BUSINESS UNDERSTANDING

Applying specific marketing strategies to different types of customers can improve results and reduce costs. Credit card customers can be profiled by the way they use, and pay off, their card.

## Business Objectives

Behavioural data can be mined to discover identifying features of clusters of customers who use their card in similar ways. The marketing department can use these insights to select target groups and optimize the marketing used to target them.
 
## Data Mining Goals

Using shallow algorithm unsupervised learning, we can discover clusters containing customers who exhibit similar behaviours. We can examine those 


# DATA UNDERSTANDING

## Collect Initial Data

Load the data from the local filesystem:

```{r message=FALSE, warning=FALSE}
#load data
df <- read.csv("credit-card-cust-behav-data.csv", stringsAsFactors = FALSE, header = TRUE, encoding  = "UTF-8")
```

Output a quick and dirty summary of the dataset, to ensure that we haven't loaded something scrambled, or the wrong thing:

```{r message=FALSE, warning=FALSE}
str(df)
```

## Describe Data

TO BE DONE.

## Explore Data

We'll plot some basic graphs, to ensure that the data conform to our limited domain understanding.

Balance vs. Credit Limit - we would expect to find a strong correlation here, even if only because those with small credit limits must have small balances. We certainly find it.

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=BALANCE, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Balance vs. Credit Limit", x="Credit Limit", y="Balance") 
```

Maybe those who pay higher portion of balance purchase more one-offs? No, this graph is pretty junky and doesn't tell us anything.

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=ONEOFF_PURCHASES_FREQUENCY, x=PRC_FULL_PAYMENT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="One-off Purchase Frequency vs. Percent of full payment paid by user", x="Percent of full payment paid by user", y="One-off Purchase Frequency") 
```

Here we can see that there appears to be a correlation between a customers credit limit, and the frequency of their purchases. Not surprising, given that frequent purchasing is one factor that leads to an increased credit limit.

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PURCHASES_FREQUENCY, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchase Frequency vs. Credit Limit", x="Credit Limit", y="Purchase Frequency") 
```

Higher credit limit, more purchases? Maybe. This graph is an excellent showcase of "outliers". Only a small handful of the 9,000 records show a credit limit, or purchases, greater than $20,000. This will be one of our guiding intuitions when we get to the Data Cleaning phase.

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PURCHASES, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchases vs. Credit Limit", x="Credit Limit", y="Purchases") 
```

It would appear that those who pay off thier balance, do not take cash advances. No surprises, but a little hard to read because of the scale. One thing that appears in this graphs is a large "column" of people who are completely unlikely to pay off their entire balance, and take cash advances with very high frequency. (It is likely that the marketing department may have less interest in these people, than in others. But we'll see!)

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=CASH_ADVANCE_FREQUENCY, x=PRC_FULL_PAYMENT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Cash Advance Frequency vs. Percent of full payment paid by user", x="Percent of full payment paid by user", y="Cash Advance Frequency") 
```

One last graph, as part of our data exploration and sanity check. This one shows that there is a clear corrleation between a customer's credit limit, and their frequency of one-off purchases. By now, we can be comfortable that our data isn't erratic, and that our limited domain knowledge isn't out to lunch.

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=ONEOFF_PURCHASES_FREQUENCY, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="One-off Purchase Frequency vs. Credit Limit", x="Credit Limit", y="One-off Purchase Frequency") 
```


## Verify Data Quality

Check if data greater than zero, look for missing data

```{r message=FALSE, warning=FALSE}
cf <- check_that(df, BALANCE > 0, BALANCE_FREQUENCY > 0, PURCHASES > 0, ONEOFF_PURCHASES > 0, INSTALLMENTS_PURCHASES > 0, CASH_ADVANCE > 0, PURCHASES_FREQUENCY > 0, ONEOFF_PURCHASES_FREQUENCY > 0, PURCHASES_INSTALLMENTS_FREQUENCY > 0, CASH_ADVANCE_FREQUENCY > 0, PURCHASES_TRX > 0, CREDIT_LIMIT > 0, MINIMUM_PAYMENTS > 0, PRC_FULL_PAYMENT > 0, TENURE > 0, BALANCE/CREDIT_LIMIT < 1)
summary(cf)
```

There appear to be a great number of zeroes. Let's look at that a little more closely:

```{r message=FALSE, warning=FALSE}
barplot(cf,main="Checks on the data set")
```

Lots of zero! Though, using our limitied knowledge of this domain, we can understand that this could be perfectly reasonable. In the first few lines of the above chart, we can see that a lot of people never make the full payment, a lot of people never get a cash advance, and some people didn't even make a purchase. Seems entirely reasonable. We can note too that the "zeroes" in PURCHASES_TRX, PURCHASES, and PURCHASES_FREQUENCY appear to be identical. In line with what we'd expect! 

Now let's include zero, and see how it all stacks up for Greater OR Equal to zero:

```{r message=FALSE, warning=FALSE}
cf <- check_that(df, BALANCE >= 0, BALANCE_FREQUENCY >= 0, PURCHASES >= 0, ONEOFF_PURCHASES >= 0, INSTALLMENTS_PURCHASES >= 0, CASH_ADVANCE >= 0, PURCHASES_FREQUENCY >= 0, ONEOFF_PURCHASES_FREQUENCY >= 0, PURCHASES_INSTALLMENTS_FREQUENCY >= 0, CASH_ADVANCE_FREQUENCY >= 0, PURCHASES_TRX >= 0, CREDIT_LIMIT >= 0, MINIMUM_PAYMENTS >= 0, PRC_FULL_PAYMENT >= 0, TENURE >= 0, BALANCE/CREDIT_LIMIT <= 1)
summary(cf)
```

Our only serious problems remaining are some N/As in Minimum Payment. We also see that a few people have a balance greater than their credit limit - this would not constitue a problem with the data. Simply a problem the customer in question is having. (Their balance is higher than their credit limit)

```{r message=FALSE, warning=FALSE}
barplot(cf,main="Checks on the data set")
```

# DATA PREPARATION

## Select Data

We will attempt to use every morsel of data in this dataset.

## Clean Data

During the Data Exploration phase, we discovered that of the 9,000 rows of data, there are a handful that have much higher values that all the rest. While we are certainly interested in these customers, they can be easily found without expensive machine learning. Simple code can be used to scrape off the customers with a credit limit, or purchases, higher than some amount.

As we're hoping to come up with customer segments that are a significant portion of our customer base, perhaps containing hundreds or thousands of customers, let's look at "capping" some of these extreme values, to see if it moderates these few extreme outliers and suggests more patterns at a smaller scale.

First, here's the graph that drew this to our attention:

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PURCHASES, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchases vs. Credit Limit", x="Credit Limit", y="Purchases") 
```

Let's cap those two variables at $20,000 and see if it seems a little less crazy:

```{r message=FALSE, warning=FALSE}
df$CREDIT_LIMIT[df$CREDIT_LIMIT > 20000 ] <- 20000
df$PURCHASES[df$PURCHASES > 20000 ] <- 20000
```

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PURCHASES, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchases vs. Credit Limit", x="Credit Limit", y="Purchases") 
```

How about if we capped them at a smaller number, would it get silly? Or would it show us more variance inside the dense part of the distribution?

```{r message=FALSE, warning=FALSE}
df$CREDIT_LIMIT[df$CREDIT_LIMIT > 10000 ] <- 10000
df$PURCHASES[df$PURCHASES > 10000 ] <- 10000
```

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PURCHASES, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchases vs. Credit Limit", x="Credit Limit", y="Purchases") 
```

Well, I don't like that. Too many Credit Limits at or above 10,000. Though, that doesn't seem a problem with Purchases.

Let's reset the data, and cap the values differently.

```{r message=FALSE, warning=FALSE}
#load data
df <- read.csv("credit-card-cust-behav-data.csv", stringsAsFactors = FALSE, header = TRUE, encoding  = "UTF-8")
 
df$CREDIT_LIMIT[df$CREDIT_LIMIT > 20000 ] <- 20000
df$PURCHASES[df$PURCHASES > 10000 ] <- 10000
 
df %>% ggplot(aes(y=PURCHASES, x=CREDIT_LIMIT)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Purchases vs. Credit Limit", x="Credit Limit", y="Purchases") 
```

That seems much better, both for the purchases, and the credit limit.

Let's look at one variable at a time, to ensure we haven't created a big distortion out at the high end:

```{r message=FALSE, warning=FALSE}
hist(df$CREDIT_LIMIT)
```

```{r message=FALSE, warning=FALSE}
hist(df$PURCHASES)
```

Seems okay. Let's look at the distribution of some of the other big-value columns, to see how they look.

```{r message=FALSE, warning=FALSE}
hist(df$CASH_ADVANCE)
```

How about Payments?

```{r message=FALSE, warning=FALSE}
hist(df$PAYMENTS)
```

```{r message=FALSE, warning=FALSE}
df %>% ggplot(aes(y=PAYMENTS, x=CASH_ADVANCE)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Payments vs. Cash Advances", x="Cash Advances", y="Payments") 
```

Wow, that's some serious outliers. Let's cap them.

```{r message=FALSE, warning=FALSE}
df <- read.csv("credit-card-cust-behav-data.csv", stringsAsFactors = FALSE, header = TRUE, encoding  = "UTF-8")
 
df$CREDIT_LIMIT[df$CREDIT_LIMIT > 20000 ] <- 20000
df$PURCHASES[df$PURCHASES > 10000 ] <- 10000
df$PAYMENTS[df$PAYMENTS > 12000 ] <- 12000
df$CASH_ADVANCE[df$CASH_ADVANCE > 8000 ] <- 8000
 
df %>% ggplot(aes(y=PAYMENTS, x=CASH_ADVANCE)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Payments vs. Cash Advances", x="Cash Advances", y="Payments") 
```

How does this look, for the individual variables?

```{r message=FALSE, warning=FALSE}
hist(df$CASH_ADVANCE)
```

```{r message=FALSE, warning=FALSE}
hist(df$PAYMENTS)
```

```{r message=FALSE, warning=FALSE}
hist(df$BALANCE_FREQUENCY)
```

Well, this is silly. Let's try something a little more "brute".

```{r message=FALSE, warning=FALSE}
df <- read.csv("credit-card-cust-behav-data.csv", stringsAsFactors = FALSE, header = TRUE, encoding  = "UTF-8")
 
# Prepare Data
df <- na.omit(df) # listwise deletion of missing
df$CUST_ID <- NULL
df$PAYMENTS <- scale(df$PAYMENTS) # standardize variables
df$CASH_ADVANCE <- scale(df$CASH_ADVANCE) # standardize variables
 
df %>% ggplot(aes(y=PAYMENTS, x=CASH_ADVANCE)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) + 
  labs(title="Payments vs. Cash Advances", x="Cash Advances", y="Payments") 
```

That's bullshit. Gonna delete that, and try harder at the other.

Actually, a "dimensionality reduction" should be considered.

## Construct Data
## Integrate Data
## Format Data


# MODELING

## Select Modeling Technique
## Generate Test Design
## Build Model Parameter Settings
## Assess Model


# EVALUATION

## Evaluate Results
## Approved Models
## Determine Next Steps


# DEPLOYMENT

## Plan Deployment
## Plan Monitoring and Maintenance
## Produce Final Report -------------------------------  KNIT THIS .Rmd FILE WHEN DONE!!!!
## Review Project